{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Einführung\n",
    "\n",
    "Im diesem Teil des Tutorials zeige ich dir die ersten Schritte mit LangChain. Dabei installieren wir die notwendigen Bibliotheken und schreiben den allerersten Basiscode um mit einem Sprachmodell wie ChatGPT (OpenAI) zu kommunizieren.\n",
    "\n",
    "\n",
    "# Warum LangChain?\n",
    "\n",
    "Die Anbieter von KIs (Sprachmodellen/LLMs) bieten häufig eigene APIs an, mit denen man mit die KI in die eigene Anwendung integrieren kann. So kann man z.B. mit der API von OpenAI bereits sehr einfach die ersten Aufrufe machen.\n",
    "Damit wir uns nicht an die API der jeweiligen Anbieter binden müssen, bietet uns LangChain uns eine einheitliche API um mit allen möglichen LLMs zu kommunizieren. Je nach Anwendungsfall können wir sogar die verschiedenen LLMs in einer Anwendung verwenden. So können wir mit einem Open-Source-Modell sog. Embeddings erstellen (mehr dazu in einem anderen Kapitel) und die Chat-Funktion von ChatGPT (OpenAI) nutzen. Wir können auch jederzeit das verwendete LLM austauschen, ohne den Code neu schreiben zu müssen.\n",
    "Zusätzlich dazu bietet LangChain vielfältige weitere Möglichkeiten. Mit den PromptTemplates können wir die Erstellung und Verwaltung von Prompts (Eingaben für die LLMs) bewerkstelligen, ohne irgendwelche Strings zusammen zu basteln. Wir können mit den Output Parsern die Ausgaben der LLMs maschinell auswerten und z.B. uns das Ergebnis als JSON zurück geben zu lassen, mit dem wir in unserem Programm arbeiten können. Spannend wird es spätestens dann, wenn wir die Agenten \"erwecken\". D.h. wir geben der KI Werkzeuge, mit denen die KI mehr als nur Texte erzeugen kann. Z.B. Informationen beschaffen, Berechnungen durchführen uvm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Installation notwendiger Bibliotheken\n",
    "\n",
    "Für die meisten Beispiele dieses Tutorial brauchen wir einige Bibliotheken. Wir brauchen natürlich die LangChain-Bibliothek. Daneben brauchen wir die OpenAI Bibliothek um mit ChatGPT zu kommunizieren (direkt aber auch unter Verwendung von LangChain). Dann benötigen wir außerdem Python Dotenv damit wir den notwendigen API-Key aus einer .env Datei laden können. Das hat den Vorteil, dass wir den geheimen API-Key nicht direkt im Code hinterlegen müssen und statt dessen in der .env Datei speichern. Diese Datei wird nicht im Git-Repository eingecheckt (in .gitignore ist diese Datei hinterlegt) und wir somit nicht aus versehen unseren API-Key veröffentlichen.\n",
    "\n",
    "Führe zunächst folgenden Befehl aus:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain in /usr/local/python/3.10.8/lib/python3.10/site-packages (0.0.310)\n",
      "Requirement already satisfied: openai in /usr/local/python/3.10.8/lib/python3.10/site-packages (0.28.1)\n",
      "Requirement already satisfied: python-dotenv in /usr/local/python/3.10.8/lib/python3.10/site-packages (1.0.0)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /home/codespace/.local/lib/python3.10/site-packages (from langchain) (6.0.1)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/python/3.10.8/lib/python3.10/site-packages (from langchain) (2.0.21)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/python/3.10.8/lib/python3.10/site-packages (from langchain) (3.8.5)\n",
      "Requirement already satisfied: anyio<4.0 in /usr/local/python/3.10.8/lib/python3.10/site-packages (from langchain) (3.7.1)\n",
      "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/python/3.10.8/lib/python3.10/site-packages (from langchain) (4.0.3)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/python/3.10.8/lib/python3.10/site-packages (from langchain) (0.6.1)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/python/3.10.8/lib/python3.10/site-packages (from langchain) (1.33)\n",
      "Requirement already satisfied: langsmith<0.1.0,>=0.0.40 in /usr/local/python/3.10.8/lib/python3.10/site-packages (from langchain) (0.0.43)\n",
      "Requirement already satisfied: numpy<2,>=1 in /home/codespace/.local/lib/python3.10/site-packages (from langchain) (1.26.0)\n",
      "Requirement already satisfied: pydantic<3,>=1 in /usr/local/python/3.10.8/lib/python3.10/site-packages (from langchain) (2.4.2)\n",
      "Requirement already satisfied: requests<3,>=2 in /home/codespace/.local/lib/python3.10/site-packages (from langchain) (2.31.0)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /home/codespace/.local/lib/python3.10/site-packages (from langchain) (8.2.3)\n",
      "Requirement already satisfied: tqdm in /usr/local/python/3.10.8/lib/python3.10/site-packages (from openai) (4.66.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/codespace/.local/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /home/codespace/.local/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (3.2.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/python/3.10.8/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/python/3.10.8/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/python/3.10.8/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/python/3.10.8/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
      "Requirement already satisfied: idna>=2.8 in /home/codespace/.local/lib/python3.10/site-packages (from anyio<4.0->langchain) (3.4)\n",
      "Requirement already satisfied: sniffio>=1.1 in /home/codespace/.local/lib/python3.10/site-packages (from anyio<4.0->langchain) (1.3.0)\n",
      "Requirement already satisfied: exceptiongroup in /home/codespace/.local/lib/python3.10/site-packages (from anyio<4.0->langchain) (1.1.3)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/python/3.10.8/lib/python3.10/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (3.20.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/python/3.10.8/lib/python3.10/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (0.9.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /home/codespace/.local/lib/python3.10/site-packages (from jsonpatch<2.0,>=1.33->langchain) (2.4)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/python/3.10.8/lib/python3.10/site-packages (from pydantic<3,>=1->langchain) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.10.1 in /usr/local/python/3.10.8/lib/python3.10/site-packages (from pydantic<3,>=1->langchain) (2.10.1)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in /home/codespace/.local/lib/python3.10/site-packages (from pydantic<3,>=1->langchain) (4.8.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/codespace/.local/lib/python3.10/site-packages (from requests<3,>=2->langchain) (2.0.5)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/codespace/.local/lib/python3.10/site-packages (from requests<3,>=2->langchain) (2023.7.22)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/python/3.10.8/lib/python3.10/site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.0)\n",
      "Requirement already satisfied: packaging>=17.0 in /home/codespace/.local/lib/python3.10/site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json<0.7,>=0.5.7->langchain) (23.1)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/python/3.10.8/lib/python3.10/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain) (1.0.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install langchain openai python-dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Beispiel: Direkte Verwendung der OpenAI-Bibliothek\n",
    "\n",
    "Bevor wir mit LangChain starten, erstmal ein Beispiel dafür, wie man die OpenAI (ChatGPT) API direkt nutzen. Das ermöglicht uns die Verwendung zu vergleichen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"id\": \"chatcmpl-87OHL8PL3oWWQr56dXBW64ri7GFgb\",\n",
      "  \"object\": \"chat.completion\",\n",
      "  \"created\": 1696772315,\n",
      "  \"model\": \"gpt-3.5-turbo-0613\",\n",
      "  \"choices\": [\n",
      "    {\n",
      "      \"index\": 0,\n",
      "      \"message\": {\n",
      "        \"role\": \"assistant\",\n",
      "        \"content\": \"Um gute Eingaben f\\u00fcr ChatGPT zu schreiben, folgen hier einige Empfehlungen:\\n\\n1. Sei spezifisch: Versuche, klare und pr\\u00e4zise Anweisungen zu geben, damit der Chatbot die gew\\u00fcnschte Aufgabe oder das gew\\u00fcnschte Ergebnis besser verstehen kann.\\n\\n2. Sei pr\\u00e4zise mit deinen Fragen: Stelle konkrete Fragen, anstatt allgemeine Aussagen zu machen. Es hilft dem Chatbot, gezielte Antworten zu geben.\\n\\n3. Vermeide doppelte Formulierungen: Wiederhole nicht denselben Satz oder dieselbe Information in verschiedenen Eingaben. Dadurch k\\u00f6nnte der Chatbot verwirrt werden.\\n\\n4. Verwende Kontext: Um eine reibungslose Konversation zu gew\\u00e4hrleisten, gib dem Chatbot klare Anhaltspunkte zur vorherigen Konversation oder zum Kontext der Fragestellung.\\n\\n5. Sei h\\u00f6flich und klar: ChatGPT reagiert positiv auf h\\u00f6fliche Anweisungen und Fragen. Verwende klare und gut formulierte S\\u00e4tze, um Missverst\\u00e4ndnisse zu vermeiden.\\n\\n6. Experimentiere und iterative Verbesserung: Wenn die vom Chatbot gelieferten Antworten nicht zufriedenstellend sind, probiere verschiedene Formulierungen oder frage in einer anderen Art und Weise nach. Durch das Experimentieren findest du heraus, wie du die besten Ergebnisse erzielen kannst.\\n\\n7. Vermeide voreingenommene oder unangemessene Fragen: ChatGPT erzeugt seine Antworten auf der Grundlage des ihm gegebenen Trainingsdatensatzes. Es ist wichtig, respektvoll zu kommunizieren und unangemessene Fragen oder Kommentare zu vermeiden.\\n\\nEs ist wichtig zu beachten, dass ChatGPT m\\u00f6glicherweise nicht immer die gew\\u00fcnschten Ergebnisse liefert. In solchen F\\u00e4llen k\\u00f6nnen iteratives Experimentieren und Reframing der Fragestellung helfen, bessere Ergebnisse zu erzielen.\"\n",
      "      },\n",
      "      \"finish_reason\": \"stop\"\n",
      "    }\n",
      "  ],\n",
      "  \"usage\": {\n",
      "    \"prompt_tokens\": 27,\n",
      "    \"completion_tokens\": 447,\n",
      "    \"total_tokens\": 474\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import openai\n",
    "\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "messages = [{\"role\": \"user\", \"content\": \"Erkläre mir bitte, wie ich gute Eingaben für ChatGPT schreibe.\"}]\n",
    "\n",
    "response = openai.ChatCompletion.create(model=\"gpt-3.5-turbo\", messages=messages)\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wir sehen, dass wir mit wenigen Zeilen Code eine Anfrage an ChatGPT senden können. Dabei fallen ein paar Sachen auf. Das erste ist, dass wir eine Liste von Nachrichten (_messages_) an die API übergeben. Außerdem enthält die Antwort wesentlich mehr, als nur den reinen Text der Antwort.\n",
    "\n",
    "Der Grund für die Liste der Nachrichten ist die, dass wir die Chat-Funktionalität nutzen. Der Server behält sich nicht die vorher eingegebenen Fragen und Antworten. D.h. man muss stets den gesamten Chat-Verlauf inkl. Antworten zurück übermitteln. Dadurch weiß die KI über welche Themen wir zuvor \"gesprochen\" haben. \n",
    "D.h. wenn ich jetzt eine Frage stellen möchte, die sich auf den bisherigen Chatverlauf bezieht, muss ich die Nachrichten-Liste erweitern:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"id\": \"chatcmpl-87OHZHS0IOI7F6Bjkd3oNhGUGMQul\",\n",
      "  \"object\": \"chat.completion\",\n",
      "  \"created\": 1696772329,\n",
      "  \"model\": \"gpt-3.5-turbo-0613\",\n",
      "  \"choices\": [\n",
      "    {\n",
      "      \"index\": 0,\n",
      "      \"message\": {\n",
      "        \"role\": \"assistant\",\n",
      "        \"content\": \"Nat\\u00fcrlich! Hier sind die wesentlichen Punkte als kurze Liste:\\n\\n1. Sei spezifisch.\\n2. Stelle pr\\u00e4zise Fragen.\\n3. Vermeide doppelte Formulierungen.\\n4. Verwende Kontext.\\n5. Sei h\\u00f6flich und klar.\\n6. Experimentiere und iteriere.\\n7. Vermeide voreingenommene oder unangemessene Fragen.\\n\\nDiese Punkte helfen dir dabei, gute Eingaben f\\u00fcr ChatGPT zu erstellen und bessere Ergebnisse zu erzielen.\"\n",
      "      },\n",
      "      \"finish_reason\": \"stop\"\n",
      "    }\n",
      "  ],\n",
      "  \"usage\": {\n",
      "    \"prompt_tokens\": 507,\n",
      "    \"completion_tokens\": 121,\n",
      "    \"total_tokens\": 628\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Die Antwort der KI muss als Nachricht in die Liste hinten angehängt werden\n",
    "messages.append(response[\"choices\"][0][\"message\"]);\n",
    "\n",
    "# Die neue Frage kommt noch dazu\n",
    "messages.append({\"role\": \"user\", \"content\": \"Danke für die Erklärung. Kannst du bitte die wesentlichen Punkte als kurze Liste zusammen fassen\"})\n",
    "\n",
    "# Erneuter Aufruf\n",
    "response = openai.ChatCompletion.create(model=\"gpt-3.5-turbo\", messages=messages)\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Natürlich! Hier sind die wesentlichen Punkte als kurze Liste:\n",
       "\n",
       "1. Sei spezifisch.\n",
       "2. Stelle präzise Fragen.\n",
       "3. Vermeide doppelte Formulierungen.\n",
       "4. Verwende Kontext.\n",
       "5. Sei höflich und klar.\n",
       "6. Experimentiere und iteriere.\n",
       "7. Vermeide voreingenommene oder unangemessene Fragen.\n",
       "\n",
       "Diese Punkte helfen dir dabei, gute Eingaben für ChatGPT zu erstellen und bessere Ergebnisse zu erzielen."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Schönere Ausgabe \n",
    "\n",
    "from IPython.display import display, Markdown\n",
    "display(Markdown(response[\"choices\"][0][\"message\"]['content']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Damit könnten wir schon eine Komplette Chat-Anwendung programmieren. Einfach Eingabe vom Benutzer holen, der Liste der Nachrichten hinzufügen, Aufruf ChatGPT, Antwort hinzufügen und das Ganze nochmal wiederholen.\n",
    "\n",
    "Lasst uns jetzt erste Schritte mit LangChain machen. Wir werden später sehen, wo uns LangChain hilft, diese Schritte zu automatisieren und wesentlich bequemer und übersichtlicher zu gestalten."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wir nutzen jetzt LangChain um mit ChatGPT zu kommunizieren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "load_dotenv(find_dotenv())\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo\")\n",
    "\n",
    "response = llm.predict(\"Spreche ich mit ChatGPT?\")\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
